{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with the Iris Dataset\n",
    "\n",
    "For an explanation of decision trees, see [our course notes](https://jennselby.github.io/MachineLearningCourseNotes/#decision-trees).\n",
    "\n",
    "This notebook uses example code from http://scikit-learn.org/stable/modules/tree.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before you can run this code, you will need to install some extra software.\n",
    "\n",
    "1. Install homebrew (if you don't already have it) following the [directions on their site](https://brew.sh/).\n",
    "1. Install the graphviz library that will let us visualize the decision tree. In Terminal, run\n",
    ">`brew install graphviz`\n",
    "1. Install the pydot library that allows you to call graphviz from Python. In Terminal run\n",
    ">`pip3 install pydot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # the iris dataset is included in scikit-learn\n",
    "from sklearn import tree # for fitting our model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# these are all needed for the particular visualization we're doing\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydot\n",
    "import os.path\n",
    "\n",
    "import numpy.random\n",
    "\n",
    "# to display graphs in this notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset\n",
    "\n",
    "Before you go on, make sure you understand this dataset. Modify the cell below to examine different parts of the dataset that are contained in the 'iris' dictionary object.\n",
    "\n",
    "What are the features? What are we trying to classify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try looking at it using a [pandas dataframe](https://jennselby.github.io/MachineLearningCourseNotes/#pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "iris_df = pandas.DataFrame(iris.data)\n",
    "iris_df.columns = iris.feature_names\n",
    "iris_df['target'] = [iris.target_names[target] for target in iris.target]\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Let's visualize our dataset, so that we can better understand what it looks like.\n",
    "\n",
    "Change the first two variables to change which features you are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two of the features (the first and fourth columns, in this case)\n",
    "x1_feature = 0\n",
    "x2_feature = 3\n",
    "\n",
    "x1 = iris.data[:,x1_feature]\n",
    "x2 = iris.data[:,x2_feature]\n",
    "\n",
    "# The data are in order by type. Find out where the other types start\n",
    "start_type_one = list(iris.target).index(1)\n",
    "start_type_two = list(iris.target).index(2)\n",
    "\n",
    "# create a figure and label it\n",
    "fig = matplotlib.pyplot.figure()\n",
    "fig.suptitle('Two Features of the Iris Data Set')\n",
    "matplotlib.pyplot.xlabel(iris.feature_names[x1_feature])\n",
    "matplotlib.pyplot.ylabel(iris.feature_names[x2_feature])\n",
    "\n",
    "# put the input data on the graph, with different colors and shapes for each type\n",
    "scatter_0 = matplotlib.pyplot.scatter(x1[:start_type_one], x2[:start_type_one],\n",
    "                                      c=\"red\", marker=\"x\", label=iris.target_names[0])\n",
    "scatter_1 = matplotlib.pyplot.scatter(x1[start_type_one:start_type_two], x2[start_type_one:start_type_two],\n",
    "                                      c=\"blue\", marker=\"^\", label=iris.target_names[1])\n",
    "scatter_2 = matplotlib.pyplot.scatter(x1[start_type_two:], x2[start_type_two:],\n",
    "                                      c=\"yellow\", marker=\"*\", label=iris.target_names[2])\n",
    "\n",
    "# add a legend to explain which points are which\n",
    "matplotlib.pyplot.legend(handles=[scatter_0, scatter_1, scatter_2])\n",
    "\n",
    "# show the graph\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Next, we want to fit our decision tree model to the iris data we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "dataSub = iris.data[:,[1,2]]\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(dataSub, iris.target)\n",
    "# model.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Model Output\n",
    "\n",
    "Using graphviz and pydot, we can create a flowchart that shows the model decisions. The flowchart will be printed to a PDF on your desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model, out_file=dot_data, feature_names=iris.feature_names[1:3], class_names=iris.target_names,\n",
    "                     filled=True, rounded=True, special_characters=True)\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]\n",
    "graph.write_pdf(os.path.expanduser(\"./iris_decision_tree.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option (Standard Difficulty)\n",
    "\n",
    "Answer the following questions. You may find it helpful to compare the PDF output to the graph above (remember you can change which columns the graph is displaying), to see the boundaries the decision tree is finding.\n",
    "\n",
    "1. According to the PDF, what feature values would tell you with high probability that you were looking at a setosa iris?\n",
    "1. According to the PDF, which features would you look at to tell a virginica from a versicolor?\n",
    "1. What is the value array in the PDF showing?\n",
    "1. Try using subsets of the input data (look at the iris_inputs variable in [LogisticRegressionIris](https://nbviewer.jupyter.org/github/jennselby/MachineLearningCourseNotes/blob/master/assets/ipynb/LogisticRegressionIris.ipynb) to see how to use only some of the columns in the model). How does this change the decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. According to the PDF if the petal length is less than or equal to 2.45 it will be a setosa\n",
    "2. Mostly petal width then petal length\n",
    "3. How many of each type of iris are possible at that point in the graph\n",
    "4. In general removing them makes the trees more complicated (probably overfit) especially if you only use the sepal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option (Advanced)\n",
    "\n",
    "Try fitting a Random Forest model to the iris data. See [this example](http://scikit-learn.org/stable/modules/ensemble.html#forest) to help you get started.\n",
    "\n",
    "How does the performance and output of Random Forest compare to the single Decision Tree? Since you can't get the graphical representation of the Random Forest model the way we did for the single Decision Tree, you'll have to think of a different way to understand what the model is doing. Think about how we can [validate the performance of our classifier models](https://jennselby.github.io/MachineLearningCourseNotes/#classification-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33)\n",
    "\n",
    "clfModel = RandomForestClassifier(n_estimators=3)\n",
    "clfModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clfModel.predict(x_test)\n",
    "print(predict == y_test)\n",
    "print(np.sum(predict == y_test)/len(predict)*100)\n",
    "#printing the correct predictions (true), incorrect (false), and percentage correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ests = {}\n",
    "for n_est in range(1,21):\n",
    "    clfModel = RandomForestClassifier(n_estimators=n_est)\n",
    "    ests[n_est] = 0\n",
    "    for i in range(100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33)\n",
    "        clfModel.fit(x_train, y_train)\n",
    "        predict = clfModel.predict(x_test)\n",
    "        ests[n_est] += (len(predict) - np.sum(predict == y_test))/100\n",
    "        \n",
    "        #testing what amount of estimators is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.scatter(range(1,len(ests)+1), list(ests.values()))\n",
    "\n",
    "#graphing the estimators with their average number of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "clfModel = RandomForestClassifier(n_estimators=3)\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33)\n",
    "clfModel.fit(x_train, y_train)\n",
    "predict = clfModel.predict(x_test)\n",
    "\n",
    "#validation\n",
    "TP = np.zeros(3)\n",
    "FP = np.zeros(3)\n",
    "TN = np.zeros(3)\n",
    "FN = np.zeros(3)\n",
    "\n",
    "for flower in range(3):\n",
    "    for i in range(len(predict)):\n",
    "        if(predict[i] == flower and predict[i] == y_test[i]):\n",
    "            TP[flower] += 1\n",
    "        if(predict[i] == flower and predict[i] != y_test[i]):\n",
    "            FP[flower] += 1\n",
    "        if(predict[i] != flower and predict[i] == y_test[i]):\n",
    "            TN[flower] += 1\n",
    "        if(predict[i] != flower and predict[i] != y_test[i]):\n",
    "            FN[flower] += 1\n",
    "    \n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f_measure = 2 * (precision*recall / (precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [1.         0.94117647 0.88888889]\n",
      "recall [0.83333333 0.88888889 0.94117647]\n",
      "f_measure [0.90909091 0.91428571 0.91428571]\n"
     ]
    }
   ],
   "source": [
    "print('precision', precision)\n",
    "print('recall', recall)\n",
    "print('f_measure', f_measure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
